{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"e\")\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "train_data=pd.read_csv(\"C:/deeplearning/sarcasm_data/train-balanced-sarcasm.csv\", encoding=\"utf-8\")\n",
    "\n",
    "train_data.drop_duplicates(inplace=True)\n",
    "train_data.dropna(inplace=True)\n",
    "\n",
    "train_df = train_data.copy()\n",
    "\n",
    "df_train = train_df.iloc[:, :2]\n",
    "\n",
    "x_train = df_train[\"comment\"]\n",
    "y_train = df_train[\"label\"]\n",
    "\n",
    "max_len = np.max(x_train.apply(lambda x: len(x)))\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "vocab_length = len(tokenizer.word_index) + 1\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = pad_sequences(x_train, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "embedding_dim = 16\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_length, embedding_dim, input_length=max_len),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True)),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "y_train = to_categorical(y_train, 3)\n",
    "\n",
    "num_epochs = 10\n",
    "history = model.fit(x_train, y_train, epochs=num_epochs, \n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
